{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25afcb45",
   "metadata": {},
   "source": [
    "# Análisis de Mortalidad Fetal en Guatemala (2012-2022) mediante Clustering K-Means\n",
    "\n",
    "Daniel Chet - 231177, Dulce Ambrosio - 231143\n",
    "\n",
    "---\n",
    "\n",
    "### Situación Problemática\n",
    "\n",
    "Guatemala registra una de las tasas de mortalidad fetal más altas de Latinoamérica. El presente proyecto busca analizar los datos oficiales de **Defunciones Fetales y Nacimientos (2012-2022)** publicados por el Instituto Nacional de Estadística (INE) para identificar patrones y perfiles de riesgo mediante técnicas de análisis exploratorio y minería de datos (K-Means). El objetivo es descubrir si existen segmentos diferenciados de la población materna que presenten mayor vulnerabilidad a la muerte fetal, considerando variables como edad, etnia, escolaridad, asistencia recibida y semanas de gestación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eabb50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Configuración de estilo\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82575844",
   "metadata": {},
   "source": [
    "## 2. Preprocesamiento de Datos\n",
    "\n",
    "El preprocesamiento enfrenta varios retos importantes:\n",
    "- Los archivos `.sav` (SPSS) de diferentes años tienen **nombres de columnas inconsistentes** (mayúsculas, minúsculas, abreviaciones distintas).\n",
    "- Algunas variables contienen valores como **\"Ignorado\"** en lugar de datos numéricos.\n",
    "- Existen **datos atípicos** en edad materna (valores como 99 o 999 que son códigos de \"no reportado\").\n",
    "- El peso al nacer viene separado en libras y onzas, y debe consolidarse.\n",
    "- Las semanas de gestación a veces vienen como texto y requieren conversión numérica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7984a9e4",
   "metadata": {},
   "source": [
    "### 2.0 Exploración de columnas originales\n",
    "\n",
    "Antes de unificar los datos, es necesario revisar qué columnas tiene cada archivo y detectar cambios en los nombres entre años. Esto nos permite construir el diccionario de mapeo que usaremos después para estandarizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b50ffadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas de DF2012:\n",
      "['DEPREG', 'MUPREG', 'MESREG', 'AÑOREG', 'DEPOCU', 'MUPOCU', 'AREAG', 'SEXO', 'DIAOCU', 'MESOCU', 'TIPAR', 'CLAPAR', 'VIAPAR', 'SEMGES', 'EDADM', 'PAISREM', 'DEPREM', 'MUPREM', 'GRETNM', 'ESCIVM', 'NACIOM', 'ESCOLAM', 'OCUPAM', 'CAUDEF', 'ASISREC', 'SITIOOCU', 'TOHITE', 'TOHINM', 'TOHIVI']\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 3157 entries, 0 to 3156\n",
      "Data columns (total 29 columns):\n",
      " #   Column    Non-Null Count  Dtype   \n",
      "---  ------    --------------  -----   \n",
      " 0   DEPREG    3157 non-null   category\n",
      " 1   MUPREG    3157 non-null   category\n",
      " 2   MESREG    3157 non-null   category\n",
      " 3   AÑOREG    3157 non-null   float64 \n",
      " 4   DEPOCU    3157 non-null   category\n",
      " 5   MUPOCU    3157 non-null   category\n",
      " 6   AREAG     3157 non-null   category\n",
      " 7   SEXO      3157 non-null   category\n",
      " 8   DIAOCU    3157 non-null   float64 \n",
      " 9   MESOCU    3157 non-null   category\n",
      " 10  TIPAR     3157 non-null   category\n",
      " 11  CLAPAR    3157 non-null   category\n",
      " 12  VIAPAR    3157 non-null   category\n",
      " 13  SEMGES    3157 non-null   category\n",
      " 14  EDADM     3157 non-null   category\n",
      " 15  PAISREM   3157 non-null   category\n",
      " 16  DEPREM    3157 non-null   category\n",
      " 17  MUPREM    3157 non-null   category\n",
      " 18  GRETNM    3157 non-null   category\n",
      " 19  ESCIVM    3157 non-null   category\n",
      " 20  NACIOM    3157 non-null   category\n",
      " 21  ESCOLAM   3157 non-null   category\n",
      " 22  OCUPAM    3157 non-null   category\n",
      " 23  CAUDEF    3157 non-null   category\n",
      " 24  ASISREC   3157 non-null   category\n",
      " 25  SITIOOCU  3157 non-null   category\n",
      " 26  TOHITE    3157 non-null   category\n",
      " 27  TOHINM    3157 non-null   category\n",
      " 28  TOHIVI    3157 non-null   category\n",
      "dtypes: category(27), float64(2)\n",
      "memory usage: 170.3 KB\n"
     ]
    }
   ],
   "source": [
    "# --- Exploración de columnas: Defunciones Fetales ---\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df_temp = pd.read_spss(\"DefuncionesFetales/DF2012.sav\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Columnas de DF2012:\")\n",
    "print(df_temp.columns.tolist())\n",
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0561dcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mBase: DF2012.sav tiene 29 columnas.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2013.sav vs año anterior ---\u001b[0m\n",
      "\u001b[93mAGREGADAS: {'PUEBLOPM', 'CIUOMAD'}\u001b[0m\n",
      "\u001b[91mELIMINADAS (o cambiaron nombre): {'OCUPAM', 'GRETNM'}\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2014.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2015.sav vs año anterior ---\u001b[0m\n",
      "\u001b[93mAGREGADAS: {'NACIONM', 'AÑOOCU'}\u001b[0m\n",
      "\u001b[91mELIMINADAS (o cambiaron nombre): {'NACIOM'}\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2016.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2017.sav vs año anterior ---\u001b[0m\n",
      "\u001b[91mELIMINADAS (o cambiaron nombre): {'AREAG'}\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2018.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2019.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2020.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2021.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando DF2022.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- Comparación de columnas entre años: Defunciones Fetales ---\n",
    "ROJO = \"\\033[91m\"\n",
    "VERDE = \"\\033[92m\"\n",
    "AMARILLO = \"\\033[93m\"\n",
    "AZUL = \"\\033[94m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "carpeta = \"DefuncionesFetales\" \n",
    "archivos = [f for f in os.listdir(carpeta) if f.endswith('.sav')]\n",
    "archivos.sort()\n",
    "\n",
    "df_prev = pd.read_spss(os.path.join(carpeta, archivos[0]))\n",
    "cols_prev = set(df_prev.columns)\n",
    "\n",
    "print(f\"{AZUL}Base: {archivos[0]} tiene {len(cols_prev)} columnas.{RESET}\")\n",
    "\n",
    "for archivo in archivos[1:]:\n",
    "    print(f\"\\n{AZUL}--- Comparando {archivo} vs año anterior ---{RESET}\")\n",
    "    \n",
    "    try:\n",
    "        df_actual = pd.read_spss(os.path.join(carpeta, archivo))\n",
    "        cols_actual = set(df_actual.columns)\n",
    "        \n",
    "        nuevas = cols_actual - cols_prev\n",
    "        if nuevas:\n",
    "            print(f\"{AMARILLO}AGREGADAS: {nuevas}{RESET}\")\n",
    "            \n",
    "        perdidas = cols_prev - cols_actual\n",
    "        if perdidas:\n",
    "            print(f\"{ROJO}ELIMINADAS (o cambiaron nombre): {perdidas}{RESET}\")\n",
    "            \n",
    "        if not nuevas and not perdidas:\n",
    "            print(f\"{VERDE}Estructura idéntica.{RESET}\")\n",
    "            \n",
    "        cols_prev = cols_actual\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{ROJO}Error leyendo {archivo}: {e}{RESET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18b37fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas de N2012:\n",
      "['Depreg', 'Mupreg', 'Mesreg', 'Añoreg', 'Depocu', 'Mupocu', 'Libras', 'Onzas', 'Diaocu', 'Mesocu', 'Sexo', 'Tipar', 'Edadp', 'Paisrep', 'Deprep', 'Muprep', 'Gretnp', 'Escivp', 'Paisnacp', 'Depnap', 'Mupnap', 'Naciop', 'Escolap', 'Ocupap', 'Edadm', 'Paisrem', 'Deprem', 'Muprem', 'grupetma', 'Escivm', 'Paisnacm', 'Depnam', 'munnam', 'Naciom', 'Escolam', 'Ocupam', 'Asisrec', 'Sitioocu', 'Tohite', 'Tohinm', 'Tohivi']\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 388613 entries, 0 to 388612\n",
      "Data columns (total 41 columns):\n",
      " #   Column    Non-Null Count   Dtype   \n",
      "---  ------    --------------   -----   \n",
      " 0   Depreg    388613 non-null  category\n",
      " 1   Mupreg    388613 non-null  category\n",
      " 2   Mesreg    388613 non-null  category\n",
      " 3   Añoreg    388613 non-null  float64 \n",
      " 4   Depocu    388613 non-null  category\n",
      " 5   Mupocu    388613 non-null  category\n",
      " 6   Libras    388613 non-null  category\n",
      " 7   Onzas     388613 non-null  category\n",
      " 8   Diaocu    388613 non-null  float64 \n",
      " 9   Mesocu    388613 non-null  category\n",
      " 10  Sexo      388613 non-null  category\n",
      " 11  Tipar     388613 non-null  category\n",
      " 12  Edadp     388613 non-null  category\n",
      " 13  Paisrep   388613 non-null  category\n",
      " 14  Deprep    388613 non-null  category\n",
      " 15  Muprep    388613 non-null  category\n",
      " 16  Gretnp    388613 non-null  category\n",
      " 17  Escivp    388613 non-null  category\n",
      " 18  Paisnacp  388613 non-null  category\n",
      " 19  Depnap    388613 non-null  category\n",
      " 20  Mupnap    388613 non-null  category\n",
      " 21  Naciop    388613 non-null  category\n",
      " 22  Escolap   388613 non-null  category\n",
      " 23  Ocupap    388613 non-null  category\n",
      " 24  Edadm     388613 non-null  category\n",
      " 25  Paisrem   388613 non-null  category\n",
      " 26  Deprem    388613 non-null  category\n",
      " 27  Muprem    388613 non-null  category\n",
      " 28  grupetma  388613 non-null  category\n",
      " 29  Escivm    388613 non-null  category\n",
      " 30  Paisnacm  388613 non-null  category\n",
      " 31  Depnam    388613 non-null  category\n",
      " 32  munnam    388613 non-null  category\n",
      " 33  Naciom    388613 non-null  category\n",
      " 34  Escolam   388613 non-null  category\n",
      " 35  Ocupam    388613 non-null  category\n",
      " 36  Asisrec   388613 non-null  category\n",
      " 37  Sitioocu  388613 non-null  category\n",
      " 38  Tohite    388613 non-null  category\n",
      " 39  Tohinm    388613 non-null  category\n",
      " 40  Tohivi    388613 non-null  category\n",
      "dtypes: category(39), float64(2)\n",
      "memory usage: 23.4 MB\n"
     ]
    }
   ],
   "source": [
    "# --- Exploración de columnas: Nacimientos ---\n",
    "df_temp = pd.read_spss(\"Nacimientos/N2012.sav\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "print(\"Columnas de N2012:\")\n",
    "print(df_temp.columns.tolist())\n",
    "df_temp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4cd7353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mBase: N2012.sav tiene 41 columnas.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2013.sav vs año anterior ---\u001b[0m\n",
      "\u001b[93mAGREGADAS: {'Mupnam', 'Ciuopad', 'Ciuomad', 'PuebloPM', 'PuebloPP'}\u001b[0m\n",
      "\u001b[91mELIMINADAS (o cambiaron nombre): {'grupetma', 'munnam', 'Gretnp', 'Ocupam', 'Ocupap'}\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2014.sav vs año anterior ---\u001b[0m\n",
      "\u001b[93mAGREGADAS: {'Munpnap', 'ciuomad', 'Ocupap'}\u001b[0m\n",
      "\u001b[91mELIMINADAS (o cambiaron nombre): {'Ciuopad', 'Naciom', 'Mupnap', 'Ciuomad', 'Naciop'}\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2015.sav vs año anterior ---\u001b[0m\n",
      "\u001b[93mAGREGADAS: {'TipoIns', 'Ocupam', 'Añoocu', 'ViaPar'}\u001b[0m\n",
      "\u001b[91mELIMINADAS (o cambiaron nombre): {'ciuomad'}\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2016.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2017.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2018.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2019.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2020.sav vs año anterior ---\u001b[0m\n",
      "\u001b[92mEstructura idéntica.\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2021.sav vs año anterior ---\u001b[0m\n",
      "\u001b[93mAGREGADAS: {'Mupnap'}\u001b[0m\n",
      "\u001b[91mELIMINADAS (o cambiaron nombre): {'Munpnap'}\u001b[0m\n",
      "\n",
      "\u001b[94m--- Comparando N2022.sav vs año anterior ---\u001b[0m\n",
      "\u001b[93mAGREGADAS: {'Pueblopp', 'Viapar', 'Pueblopm'}\u001b[0m\n",
      "\u001b[91mELIMINADAS (o cambiaron nombre): {'ViaPar', 'PuebloPP', 'PuebloPM'}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- Comparación de columnas entre años: Nacimientos ---\n",
    "carpeta = \"Nacimientos\" \n",
    "archivos = [f for f in os.listdir(carpeta) if f.endswith('.sav')]\n",
    "archivos.sort()\n",
    "\n",
    "df_prev = pd.read_spss(os.path.join(carpeta, archivos[0]))\n",
    "cols_prev = set(df_prev.columns)\n",
    "\n",
    "print(f\"{AZUL}Base: {archivos[0]} tiene {len(cols_prev)} columnas.{RESET}\")\n",
    "\n",
    "for archivo in archivos[1:]:\n",
    "    print(f\"\\n{AZUL}--- Comparando {archivo} vs año anterior ---{RESET}\")\n",
    "    \n",
    "    try:\n",
    "        df_actual = pd.read_spss(os.path.join(carpeta, archivo))\n",
    "        cols_actual = set(df_actual.columns)\n",
    "        \n",
    "        nuevas = cols_actual - cols_prev\n",
    "        if nuevas:\n",
    "            print(f\"{AMARILLO}AGREGADAS: {nuevas}{RESET}\")\n",
    "            \n",
    "        perdidas = cols_prev - cols_actual\n",
    "        if perdidas:\n",
    "            print(f\"{ROJO}ELIMINADAS (o cambiaron nombre): {perdidas}{RESET}\")\n",
    "            \n",
    "        if not nuevas and not perdidas:\n",
    "            print(f\"{VERDE}Estructura idéntica.{RESET}\")\n",
    "            \n",
    "        cols_prev = cols_actual\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{ROJO}Error leyendo {archivo}: {e}{RESET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445ed32",
   "metadata": {},
   "source": [
    "### 2.1 Lectura de archivos de Nacimientos (2012-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de66a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando 11 archivos de Nacimientos (2012-2022)...\n",
      "  -> N2012.sav: OK\n",
      "  -> N2013.sav: OK\n",
      "  -> N2014.sav: OK\n",
      "  -> N2015.sav: OK\n",
      "  -> N2016.sav: OK\n",
      "  -> N2017.sav: OK\n",
      "  -> N2018.sav: OK\n",
      "  -> N2019.sav: OK\n",
      "  -> N2020.sav: OK\n",
      "  -> N2021.sav: OK\n",
      "  -> N2022.sav: OK\n",
      "\n",
      "Calculando pesos y limpiando...\n",
      "\n",
      "--- RESUMEN FINAL ---\n",
      "<class 'pandas.DataFrame'>\n",
      "Index: 4103769 entries, 0 to 4107968\n",
      "Data columns (total 14 columns):\n",
      " #   Column               Dtype   \n",
      "---  ------               -----   \n",
      " 0   Departamento         category\n",
      " 1   Municipio            object  \n",
      " 2   Anio                 float64 \n",
      " 3   Mes                  category\n",
      " 4   Edad_Madre           object  \n",
      " 5   Estado_Civil         category\n",
      " 6   Escolaridad          str     \n",
      " 7   Total_Hijos          object  \n",
      " 8   Pueblo_Etnia         str     \n",
      " 9   Sexo                 category\n",
      " 10  Tipo_Parto           str     \n",
      " 11  Sitio_Ocurrencia     str     \n",
      " 12  Asistencia_Recibida  str     \n",
      " 13  Peso_Libras          float64 \n",
      "dtypes: category(4), float64(2), object(3), str(5)\n",
      "memory usage: 541.6+ MB\n",
      "None\n",
      "\n",
      "Primeras 5 filas:\n",
      "  Departamento    Municipio    Anio        Mes Edad_Madre Estado_Civil  \\\n",
      "0    Guatemala    Amatitlán  2012.0  Noviembre       26.0      Soltera   \n",
      "1    Guatemala    Guatemala  2012.0      Abril       30.0       Casada   \n",
      "2    Guatemala    Guatemala  2012.0  Diciembre       38.0       Casada   \n",
      "3    Guatemala  Villa Nueva  2012.0      Enero       35.0       Casada   \n",
      "4    Guatemala    Guatemala  2012.0      Enero       34.0       Casada   \n",
      "\n",
      "     Escolaridad Total_Hijos Pueblo_Etnia    Sexo Tipo_Parto  \\\n",
      "0  Diversificado         1.0  No indigena  Hombre     Simple   \n",
      "1       Ignorado         1.0     Ignorado  Hombre     Simple   \n",
      "2  Universitario         1.0  No indigena  Hombre     Simple   \n",
      "3  Diversificado         2.0  No indigena  Hombre     Simple   \n",
      "4  Diversificado    Ignorado  No indigena   Mujer     Simple   \n",
      "\n",
      "   Sitio_Ocurrencia Asistencia_Recibida  Peso_Libras  \n",
      "0  Hospital privado              Médica       5.5000  \n",
      "1  Hospital privado              Médica       5.4375  \n",
      "2  Hospital privado              Médica       7.0625  \n",
      "3  Hospital privado              Médica       9.5625  \n",
      "4  Hospital privado              Médica       6.1250  \n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURACIÓN ---\n",
    "carpeta_nacimientos = \"./Nacimientos/\"\n",
    "\n",
    "# DICCIONARIO DE COLUMNAS A CONSERVAR\n",
    "cols_nacimientos_map = {\n",
    "    # --- Geografía (Residencia es mejor que Ocurrencia para análisis social) ---\n",
    "    'Departamento': ['Deprem', 'DEPREM'],\n",
    "    'Municipio': ['Muprem', 'MUPREM'],\n",
    "    \n",
    "    # --- Tiempo ---\n",
    "    'Anio': ['Añoocu', 'AÑOOCU', 'Añoreg', 'AÑOREG', 'Anoreg'],\n",
    "    'Mes': ['Mesocu', 'MESOCU', 'Mesreg', 'MESREG'],\n",
    "    \n",
    "    # --- Datos Madre ---\n",
    "    'Edad_Madre': ['Edadm', 'EDADM'],\n",
    "    'Estado_Civil': ['Escivm', 'ESCIVM'],\n",
    "    'Escolaridad': ['Escolam', 'ESCOLAM'],\n",
    "    'Total_Hijos': ['Tohite', 'TOHITE'],\n",
    "    'Pueblo_Etnia': ['PuebloPM', 'PUEBLOPM', 'Pueblopm', 'grupetma', 'GRUPETMA'],\n",
    "    \n",
    "    # --- Datos Bebé ---\n",
    "    'Sexo': ['Sexo', 'SEXO'],\n",
    "    'Tipo_Parto': ['Tipar', 'TIPAR'],\n",
    "    'Sitio_Ocurrencia': ['Sitioocu', 'SITIOOCU'],\n",
    "    'Asistencia_Recibida': ['Asisrec', 'ASISREC'],\n",
    "    \n",
    "    # --- Peso (temporales para cálculo) ---\n",
    "    'Libras_Temp': ['Libras', 'LIBRAS'],\n",
    "    'Onzas_Temp': ['Onzas', 'ONZAS']\n",
    "}\n",
    "\n",
    "def procesar_nacimientos(carpeta, diccionario_map):\n",
    "    archivos = [f for f in os.listdir(carpeta) if f.endswith('.sav')]\n",
    "    archivos.sort()\n",
    "    archivos = [f for f in archivos if any(str(y) in f for y in range(2012, 2023))]\n",
    "    \n",
    "    lista_dfs = []\n",
    "    print(f\"Procesando {len(archivos)} archivos de Nacimientos (2012-2022)...\")\n",
    "    \n",
    "    for archivo in archivos:\n",
    "        ruta = os.path.join(carpeta, archivo)\n",
    "        try:\n",
    "            df_raw = pd.read_spss(ruta, convert_categoricals=True)\n",
    "            df_limpio = pd.DataFrame()\n",
    "            \n",
    "            for nombre_final, variantes in diccionario_map.items():\n",
    "                col_encontrada = None\n",
    "                for col_real in df_raw.columns:\n",
    "                    if col_real.upper() in [v.upper() for v in variantes]:\n",
    "                        col_encontrada = col_real\n",
    "                        break\n",
    "                if col_encontrada:\n",
    "                    df_limpio[nombre_final] = df_raw[col_encontrada]\n",
    "                else:\n",
    "                    df_limpio[nombre_final] = np.nan\n",
    "            \n",
    "            lista_dfs.append(df_limpio)\n",
    "            print(f\"  -> {archivo}: OK\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR en {archivo}: {e}\")\n",
    "\n",
    "    if not lista_dfs:\n",
    "        return None\n",
    "\n",
    "    df_final = pd.concat(lista_dfs, ignore_index=True)\n",
    "    \n",
    "    print(\"\\nCalculando pesos y limpiando...\")\n",
    "    df_final['Libras_Temp'] = pd.to_numeric(df_final['Libras_Temp'], errors='coerce').fillna(0)\n",
    "    df_final['Onzas_Temp'] = pd.to_numeric(df_final['Onzas_Temp'], errors='coerce').fillna(0)\n",
    "    df_final['Peso_Libras'] = df_final['Libras_Temp'] + (df_final['Onzas_Temp'] / 16)\n",
    "    df_final = df_final.drop(columns=['Libras_Temp', 'Onzas_Temp'])\n",
    "    df_final = df_final[df_final['Peso_Libras'] > 0]\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# --- EJECUTAR ---\n",
    "df_nacimientos = procesar_nacimientos(carpeta_nacimientos, cols_nacimientos_map)\n",
    "\n",
    "print(\"\\n--- RESUMEN FINAL ---\")\n",
    "print(df_nacimientos.info())\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "print(df_nacimientos.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93113058",
   "metadata": {},
   "source": [
    "### 2.2 Lectura de archivos de Defunciones Fetales (2012-2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f8670c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando 11 archivos de Defunciones (2012-2022)...\n",
      "  -> DF2012.sav: OK\n",
      "  -> DF2013.sav: OK\n",
      "  -> DF2014.sav: OK\n",
      "  -> DF2015.sav: OK\n",
      "  -> DF2016.sav: OK\n",
      "  -> DF2017.sav: OK\n",
      "  -> DF2018.sav: OK\n",
      "  -> DF2019.sav: OK\n",
      "  -> DF2020.sav: OK\n",
      "  -> DF2021.sav: OK\n",
      "  -> DF2022.sav: OK\n",
      "\n",
      "Limpiando datos numéricos...\n",
      "\n",
      "--- RESUMEN FINAL DEFUNCIONES ---\n",
      "<class 'pandas.DataFrame'>\n",
      "Index: 28897 entries, 0 to 31606\n",
      "Data columns (total 15 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   Departamento         28897 non-null  str     \n",
      " 1   Municipio            28897 non-null  str     \n",
      " 2   Anio                 28897 non-null  float64 \n",
      " 3   Mes                  28897 non-null  category\n",
      " 4   Edad_Madre           28163 non-null  float64 \n",
      " 5   Estado_Civil         28897 non-null  category\n",
      " 6   Escolaridad          28897 non-null  str     \n",
      " 7   Total_Hijos          28602 non-null  object  \n",
      " 8   Pueblo_Etnia         28897 non-null  str     \n",
      " 9   Sexo                 28897 non-null  category\n",
      " 10  Tipo_Parto           28897 non-null  str     \n",
      " 11  Sitio_Ocurrencia     28897 non-null  category\n",
      " 12  Asistencia_Recibida  28897 non-null  category\n",
      " 13  Causa_Defuncion      28897 non-null  str     \n",
      " 14  Semanas_Gestacion    28897 non-null  float64 \n",
      "dtypes: category(5), float64(3), object(1), str(6)\n",
      "memory usage: 4.1+ MB\n",
      "None\n",
      "\n",
      "Primeras 5 filas:\n",
      "   Departamento    Municipio    Anio        Mes  Edad_Madre Estado_Civil  \\\n",
      "0     Guatemala    Guatemala  2012.0      Abril        27.0      Soltero   \n",
      "1     Guatemala  Villa Nueva  2012.0  Noviembre        41.0       Casado   \n",
      "2  Alta Verapaz        Cobán  2012.0       Mayo        29.0       Casado   \n",
      "3   El Progreso     Sanarate  2012.0  Diciembre        38.0      Soltero   \n",
      "5     Guatemala    Fraijanes  2012.0  Noviembre        33.0      Soltero   \n",
      "\n",
      "     Escolaridad Total_Hijos Pueblo_Etnia    Sexo Tipo_Parto  \\\n",
      "0  Diversificado    Ignorado     Ignorado  Hombre     Simple   \n",
      "1  Diversificado         4.0  No indigena   Mujer     Simple   \n",
      "2  Universitario    Ignorado  No indigena  Hombre     Simple   \n",
      "3         Básico         2.0  No indigena  Hombre     Simple   \n",
      "5  Universitario         2.0  No indigena   Mujer     Simple   \n",
      "\n",
      "   Sitio_Ocurrencia Asistencia_Recibida  \\\n",
      "0  Hospital Privado              Médica   \n",
      "1  Hospital Privado              Médica   \n",
      "2     Seguro Social              Médica   \n",
      "3     Seguro Social              Médica   \n",
      "5  Hospital Privado              Médica   \n",
      "\n",
      "                                     Causa_Defuncion  Semanas_Gestacion  \n",
      "0              Hipoxia intrauterina, no especificada               27.0  \n",
      "1              Muerte fetal de causa no especificada               30.0  \n",
      "2              Hipoxia intrauterina, no especificada               23.0  \n",
      "3                     Aspiración neonatal de meconio               25.0  \n",
      "5  Feto y recién nacido afectados por otras forma...               34.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# --- CONFIGURACIÓN ---\n",
    "# Ajusta la ruta a donde tengas tus archivos de DEFUNCIONES\n",
    "carpeta_defunciones = \"./DefuncionesFetales/\" \n",
    "\n",
    "# DICCIONARIO DE COLUMNAS A CONSERVAR (Defunciones Fetales)\n",
    "cols_defunciones_map = {\n",
    "    # --- Geografía (Usamos Residencia para cruzar con Nacimientos) ---\n",
    "    'Departamento': ['DEPREM', 'Deprem'],\n",
    "    'Municipio': ['MUPREM', 'Muprem'],\n",
    "    \n",
    "    # --- Tiempo ---\n",
    "    # Prioridad: Ocurrencia. Si no existe, Registro.\n",
    "    'Anio': ['AÑOOCU', 'Añoocu', 'AÑOREG', 'Añoreg', 'ANOREG'],\n",
    "    'Mes': ['MESOCU', 'Mesocu', 'MESREG', 'Mesreg'],\n",
    "    \n",
    "    # --- Datos Madre ---\n",
    "    'Edad_Madre': ['EDADM', 'Edadm'],\n",
    "    'Estado_Civil': ['ESCIVM', 'Escivm'],\n",
    "    'Escolaridad': ['ESCOLAM', 'Escolam'],\n",
    "    'Total_Hijos': ['TOHITE', 'Tohite'],\n",
    "    # El cambio difícil: GRETNM -> PUEBLOPM -> NACIONM (a veces)\n",
    "    'Pueblo_Etnia': ['PUEBLOPM', 'PuebloPM', 'Pueblopm', 'GRETNM', 'Gretnm'],\n",
    "    \n",
    "    # --- Datos Feto/Evento ---\n",
    "    'Sexo': ['SEXO', 'Sexo'],\n",
    "    'Tipo_Parto': ['TIPAR', 'Tipar'],\n",
    "    'Sitio_Ocurrencia': ['SITIOOCU', 'Sitioocu'],\n",
    "    'Asistencia_Recibida': ['ASISREC', 'Asisrec'],\n",
    "    'Causa_Defuncion': ['CAUDEF', 'Caudef'], # Muy importante en defunciones\n",
    "    \n",
    "    # --- Variable Numérica Crítica ---\n",
    "    'Semanas_Gestacion': ['SEMGES', 'Semges']\n",
    "}\n",
    "\n",
    "def procesar_defunciones(carpeta, diccionario_map):\n",
    "    archivos = [f for f in os.listdir(carpeta) if f.endswith('.sav')]\n",
    "    archivos.sort()\n",
    "    \n",
    "    # Filtro 2012-2022\n",
    "    archivos = [f for f in archivos if any(str(y) in f for y in range(2012, 2023))]\n",
    "    \n",
    "    lista_dfs = []\n",
    "    print(f\"Procesando {len(archivos)} archivos de Defunciones (2012-2022)...\")\n",
    "    \n",
    "    for archivo in archivos:\n",
    "        ruta = os.path.join(carpeta, archivo)\n",
    "        try:\n",
    "            # Leer archivo con etiquetas\n",
    "            df_raw = pd.read_spss(ruta, convert_categoricals=True)\n",
    "            \n",
    "            df_limpio = pd.DataFrame()\n",
    "            \n",
    "            for nombre_final, variantes in diccionario_map.items():\n",
    "                col_encontrada = None\n",
    "                for col_real in df_raw.columns:\n",
    "                    if col_real.upper() in [v.upper() for v in variantes]:\n",
    "                        col_encontrada = col_real\n",
    "                        break\n",
    "                \n",
    "                if col_encontrada:\n",
    "                    df_limpio[nombre_final] = df_raw[col_encontrada]\n",
    "                else:\n",
    "                    df_limpio[nombre_final] = np.nan\n",
    "            \n",
    "            lista_dfs.append(df_limpio)\n",
    "            print(f\"  -> {archivo}: OK\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ERROR en {archivo}: {e}\")\n",
    "\n",
    "    if not lista_dfs:\n",
    "        return None\n",
    "\n",
    "    # 1. Unir todo\n",
    "    df_final = pd.concat(lista_dfs, ignore_index=True)\n",
    "    \n",
    "    # 2. LIMPIEZA ESPECÍFICA DE DEFUNCIONES\n",
    "    print(\"\\nLimpiando datos numéricos...\")\n",
    "    \n",
    "    # Semanas de Gestación: Debe ser numérico.\n",
    "    # A veces viene como \"Ignorado\" o texto. 'coerce' lo vuelve NaN.\n",
    "    df_final['Semanas_Gestacion'] = pd.to_numeric(df_final['Semanas_Gestacion'], errors='coerce')\n",
    "    \n",
    "    # Edad Madre: Asegurar numérico\n",
    "    df_final['Edad_Madre'] = pd.to_numeric(df_final['Edad_Madre'], errors='coerce')\n",
    "    \n",
    "    # Eliminar registros sin semanas de gestación válidas (opcional, pero recomendado para K-Means)\n",
    "    df_final = df_final.dropna(subset=['Semanas_Gestacion'])\n",
    "\n",
    "    return df_final\n",
    "\n",
    "# --- EJECUTAR ---\n",
    "df_defunciones = procesar_defunciones(carpeta_defunciones, cols_defunciones_map)\n",
    "\n",
    "# Verificación\n",
    "if df_defunciones is not None:\n",
    "    print(\"\\n--- RESUMEN FINAL DEFUNCIONES ---\")\n",
    "    print(df_defunciones.info())\n",
    "    print(\"\\nPrimeras 5 filas:\")\n",
    "    print(df_defunciones.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b6ebb",
   "metadata": {},
   "source": [
    "### 2.3 Estandarización de nombres y limpieza de variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe37abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración de estilo (para que se vean profesionales como en el notebook de clase)\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8761c66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpieza de Edad completada.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Limpiar Edad en Nacimientos (Convertir \"Ignorado\" a NaN)\n",
    "# errors='coerce' fuerza a que cualquier texto se vuelva un número vacío (NaN)\n",
    "df_nacimientos['Edad_Madre'] = pd.to_numeric(df_nacimientos['Edad_Madre'], errors='coerce')\n",
    "\n",
    "# 2. Eliminar las filas que quedaron vacías (NaN) en esa columna\n",
    "df_nacimientos = df_nacimientos.dropna(subset=['Edad_Madre'])\n",
    "\n",
    "# 3. (Opcional pero recomendado) Hacer lo mismo con Defunciones por seguridad\n",
    "df_defunciones['Edad_Madre'] = pd.to_numeric(df_defunciones['Edad_Madre'], errors='coerce')\n",
    "df_defunciones = df_defunciones.dropna(subset=['Edad_Madre'])\n",
    "\n",
    "print(\"Limpieza de Edad completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "825377b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Limpieza de Valores Atípicos en Peso ---\n",
      "Se encontraron 270 registros con peso mayor a 15 libras. Serán eliminados.\n",
      "Limpieza de peso completada. Los QQ-Plots ahora se verán normales.\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Limpieza de Valores Atípicos en Peso ---\")\n",
    "\n",
    "# Ver cuántos datos raros hay antes de borrar\n",
    "pesos_raros = df_nacimientos[df_nacimientos['Peso_Libras'] > 15].shape[0]\n",
    "print(f\"Se encontraron {pesos_raros} registros con peso mayor a 15 libras. Serán eliminados.\")\n",
    "\n",
    "# Filtrar para mantener solo pesos biológicamente posibles (ej. entre 1 y 15 libras)\n",
    "df_nacimientos = df_nacimientos[(df_nacimientos['Peso_Libras'] >= 1) & (df_nacimientos['Peso_Libras'] <= 15)]\n",
    "\n",
    "print(\"Limpieza de peso completada. Los QQ-Plots ahora se verán normales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84673bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Estandarización Profunda de Variables Categóricas ---\n",
      "¡Limpieza profunda completada!\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Estandarización Profunda de Variables Categóricas ---\")\n",
    "\n",
    "# 1. Diccionario extendido para Asistencia Recibida\n",
    "mapeo_asistencia_ext = {\n",
    "    'Médico': 'Médica',\n",
    "    'Medico': 'Médica',\n",
    "    'Empírico': 'Empírica',\n",
    "    'Empirico': 'Empírica',\n",
    "    'Paramédico': 'Paramédica',\n",
    "    'Paramedico': 'Paramédica',\n",
    "    'Ninguno': 'Ninguna',\n",
    "    'Ignorada': 'Ignorado'\n",
    "}\n",
    "\n",
    "# 2. Diccionario extendido para Etnia\n",
    "# Asumimos 'Indigena' como 'Maya' (el grupo mayoritario) y 'No indigena' como 'Mestizo / Ladino'\n",
    "mapeo_etnia_ext = {\n",
    "    'Xinca': 'Xinka',\n",
    "    'Indigena': 'Maya',\n",
    "    'No indigena': 'Mestizo / Ladino'\n",
    "}\n",
    "\n",
    "# 3. Aplicar los mapeos a Nacimientos\n",
    "df_nacimientos['Asistencia_Recibida'] = df_nacimientos['Asistencia_Recibida'].replace(mapeo_asistencia_ext)\n",
    "df_nacimientos['Pueblo_Etnia'] = df_nacimientos['Pueblo_Etnia'].replace(mapeo_etnia_ext)\n",
    "\n",
    "# 4. Aplicar los mapeos a Defunciones (para mantener coherencia entre ambas tablas)\n",
    "df_defunciones['Asistencia_Recibida'] = df_defunciones['Asistencia_Recibida'].replace(mapeo_asistencia_ext)\n",
    "df_defunciones['Pueblo_Etnia'] = df_defunciones['Pueblo_Etnia'].replace(mapeo_etnia_ext)\n",
    "\n",
    "print(\"¡Limpieza profunda completada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6870d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Limpieza de variables numéricas completada!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Función para limpiar columnas numéricas a la fuerza\n",
    "def limpiar_numericos(df, columnas):\n",
    "    for col in columnas:\n",
    "        # Convertir a numérico, errores se vuelven NaN\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "# 1. Definir las columnas numéricas que vas a usar\n",
    "cols_num_nac = ['Edad_Madre', 'Peso_Libras', 'Total_Hijos']\n",
    "cols_num_def = ['Edad_Madre', 'Semanas_Gestacion', 'Total_Hijos']\n",
    "\n",
    "# 2. Aplicar limpieza\n",
    "df_nacimientos = limpiar_numericos(df_nacimientos, cols_num_nac)\n",
    "df_defunciones = limpiar_numericos(df_defunciones, cols_num_def)\n",
    "\n",
    "# 3. Eliminar filas que quedaron vacías por tener datos inválidos\n",
    "df_nacimientos = df_nacimientos.dropna(subset=cols_num_nac)\n",
    "df_defunciones = df_defunciones.dropna(subset=cols_num_def)\n",
    "\n",
    "print(\"¡Limpieza de variables numéricas completada!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
